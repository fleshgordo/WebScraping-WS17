{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watson IBM API\n",
    "\n",
    "Watson ist ein Computerprogramm aus dem Bereich der Künstlichen Intelligenz. Es wurde von IBM entwickelt, um Antworten auf Fragen zu geben, die in digitaler Form in natürlicher Sprache eingegeben werden. Mittlerweile bietet IBM verschiedenste Künstliche Intelligenz Algorithmen an, welche man mit einer API \"relativ\" einfach abfragen kann.\n",
    "\n",
    "Es gibt eine Python Bibliothek die eine Schnittstelle zu den Services von Watson bereitstellt. Hier der direkte [Link](https://github.com/watson-developer-cloud/python-sdk). Am besten installiert man sie im Terminal mit:\n",
    "\n",
    "```\n",
    "pip install --upgrade watson-developer-cloud\n",
    "```\n",
    "\n",
    "Nach der Installation, muss man das Jupyter Notebook schliessen bzw. beenden (CTRL+C) und den Terminal ebenso. Danach wieder das Terminal Programm starten und stellt sicher dass eure Python Umgebung korrekt ist.\n",
    "\n",
    "```\n",
    "source activate blockwoche\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gesichtserkennung\n",
    "\n",
    "Bei der Gesichtserkennung kann man ein Bild an den Watson Server schicken, welcher es mit einem Gesichtserkennungs-Algorithmus interpretiert und die Resultate in Textform zurückgibt. \n",
    "\n",
    "Zunächst müssen einige Bibliotheken in Python importiert werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from os.path import join, dirname\n",
    "from os import environ\n",
    "from watson_developer_cloud import VisualRecognitionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Danach muss eine Variable initialisert werden, welche als Objekt/Interface zum Watson verschiedenste Methoden anbietet. Dabei muss auch der Developer Key angegeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visual_recognition = VisualRecognitionV3('2016-05-20', api_key='a5c120b7f1e3c757f64b0ba87af00b2d8283c8f6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falls der API key ungültig ist, dann bekommt ihr eine Fehlermeldung in der oberen Zeile. Ihr müsst in eurem [Bluemix](https://console.bluemix.net) nachsehen, ob ihr eine Applikation für Image Recognition angemeldet habt.\n",
    "\n",
    "Das Objekt **visual_recognition** bietet nun verschiedene Funktionen an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-20\n"
     ]
    }
   ],
   "source": [
    "print (visual_recognition.version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun kann man eine Funktion **detect_faces** abrufen. Man muss ihr aber einen Link zu einem File schicken mit dem Parameter **images_url**. Das ganze wird in der Variable resultat gespeichert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'images': [{u'source_url': u'https://www.trend.at/_storage/asset/5523414/storage/vgnat:twocolumn_930:575/file/76775962/merkel-roboter.jpg', u'resolved_url': u'https://www.trend.at/_storage/asset/5523414/storage/vgnat:twocolumn_930:575/file/76775962/merkel-roboter.jpg', u'faces': [{u'gender': {u'gender': u'FEMALE', u'score': 0.0179862}, u'age': {u'score': 0.492712, u'min': 65}, u'face_location': {u'width': 209, u'top': 103, u'left': 530, u'height': 215}}]}], u'images_processed': 1}\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ergebnis ist nun wieder im JSON Format. Mit der Funktion **json** kann man die Textausgable etwas übersichtlicher gestalten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"images\": [\n",
      "    {\n",
      "      \"source_url\": \"https://www.trend.at/_storage/asset/5523414/storage/vgnat:twocolumn_930:575/file/76775962/merkel-roboter.jpg\", \n",
      "      \"resolved_url\": \"https://www.trend.at/_storage/asset/5523414/storage/vgnat:twocolumn_930:575/file/76775962/merkel-roboter.jpg\", \n",
      "      \"faces\": [\n",
      "        {\n",
      "          \"gender\": {\n",
      "            \"gender\": \"FEMALE\", \n",
      "            \"score\": 0.0179862\n",
      "          }, \n",
      "          \"age\": {\n",
      "            \"score\": 0.492712, \n",
      "            \"min\": 65\n",
      "          }, \n",
      "          \"face_location\": {\n",
      "            \"width\": 209, \n",
      "            \"top\": 103, \n",
      "            \"left\": 530, \n",
      "            \"height\": 215\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ], \n",
      "  \"images_processed\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(resultat, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei der Antwort handelt es sich um Pyhton Dictionary. Bei einem Dictionary gibt es immer ein Key/Value Pair. Der Key ist \"images\" und der Value besteht eigentlich aus einem Array. Um nun nur das Gender anzeigen zu lassen, muss man das Ergebnis etwas filtern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'gender': u'FEMALE', u'score': 0.0179862}\n"
     ]
    }
   ],
   "source": [
    "print resultat[\"images\"][0][\"faces\"][0][\"gender\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um tatsächlich nur das Geschlecht anzuzuzeigen braucht man folgendes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEMALE\n"
     ]
    }
   ],
   "source": [
    "print resultat[\"images\"][0][\"faces\"][0][\"gender\"][\"gender\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oder das Alter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "print resultat[\"images\"][0][\"faces\"][0][\"age\"][\"min\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier der ganze Code um das Geschlecht bzw. Alter der Person zu ermitteln:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"images\": [\n",
      "    {\n",
      "      \"source_url\": \"https://www.trend.at/_storage/asset/5523414/storage/vgnat:twocolumn_930:575/file/76775962/merkel-roboter.jpg\", \n",
      "      \"resolved_url\": \"https://www.trend.at/_storage/asset/5523414/storage/vgnat:twocolumn_930:575/file/76775962/merkel-roboter.jpg\", \n",
      "      \"faces\": [\n",
      "        {\n",
      "          \"gender\": {\n",
      "            \"gender\": \"FEMALE\", \n",
      "            \"score\": 0.0179862\n",
      "          }, \n",
      "          \"age\": {\n",
      "            \"score\": 0.492712, \n",
      "            \"min\": 65\n",
      "          }, \n",
      "          \"face_location\": {\n",
      "            \"width\": 209, \n",
      "            \"top\": 103, \n",
      "            \"left\": 530, \n",
      "            \"height\": 215\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ], \n",
      "  \"images_processed\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from os.path import join, dirname\n",
    "from os import environ\n",
    "from watson_developer_cloud import VisualRecognitionV3\n",
    "\n",
    "visual_recognition = VisualRecognitionV3('2016-05-20', api_key='a5c120b7f1e3c757f64b0ba87af00b2d8283c8f6')\n",
    "\n",
    "resultat = visual_recognition.detect_faces(images_url=\"https://www.trend.at/_storage/asset/5523414/storage/vgnat:twocolumn_930:575/file/76775962/merkel-roboter.jpg\")\n",
    "print(json.dumps(resultat, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification\n",
    "\n",
    "Hier wird Maschinelles Lernen (machine learning) angewendet, um sogenannte Keywords aus einem Bild herauszulesen. Der Computer \"sieht\" das Bild und gibt kontextspezifische Keywords zurück. Der Watson Computer wurde mit einer riesigen Menge an Bildern gefüttert. Man kann nun ein Bild an die Watson API schicken und der Computer (mit extrem hoher Rechenkraft) versucht es zu analysieren und danach mit einem neuralen Netzwerk zu interpretieren.  \n",
    "\n",
    "Man muss wie gehabt zunächst die Bibliotheken importieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from os.path import join, dirname\n",
    "from os import environ\n",
    "from watson_developer_cloud import VisualRecognitionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Danach erzeuge wir wieder die Schnittstelle mit der Watson API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visual_recognition = VisualRecognitionV3('2016-05-20', api_key='a5c120b7f1e3c757f64b0ba87af00b2d8283c8f6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun kann man die **classify** Funktion aufrufen mit einem Link zu einem Bild:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bildLink = \"http://feelectronica.de/wp-content/uploads/2015/07/TechnoViking.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"images\": [\n",
      "    {\n",
      "      \"classifiers\": [\n",
      "        {\n",
      "          \"classes\": [\n",
      "            {\n",
      "              \"score\": 0.572, \n",
      "              \"class\": \"Demonstration\", \n",
      "              \"type_hierarchy\": \"/person/Demonstration\"\n",
      "            }, \n",
      "            {\n",
      "              \"score\": 0.678, \n",
      "              \"class\": \"person\"\n",
      "            }, \n",
      "            {\n",
      "              \"score\": 0.569, \n",
      "              \"class\": \"people\", \n",
      "              \"type_hierarchy\": \"/person/people\"\n",
      "            }, \n",
      "            {\n",
      "              \"score\": 0.521, \n",
      "              \"class\": \"marcher\", \n",
      "              \"type_hierarchy\": \"/person/traveler/marcher\"\n",
      "            }, \n",
      "            {\n",
      "              \"score\": 0.523, \n",
      "              \"class\": \"traveler\"\n",
      "            }, \n",
      "            {\n",
      "              \"score\": 0.52, \n",
      "              \"class\": \"shofar (musical horn)\", \n",
      "              \"type_hierarchy\": \"/horn/shofar (musical horn)\"\n",
      "            }, \n",
      "            {\n",
      "              \"score\": 0.52, \n",
      "              \"class\": \"horn\"\n",
      "            }, \n",
      "            {\n",
      "              \"score\": 0.5, \n",
      "              \"class\": \"crowd\", \n",
      "              \"type_hierarchy\": \"/people/crowd\"\n",
      "            }, \n",
      "            {\n",
      "              \"score\": 0.801, \n",
      "              \"class\": \"alizarine red color\"\n",
      "            }\n",
      "          ], \n",
      "          \"classifier_id\": \"default\", \n",
      "          \"name\": \"default\"\n",
      "        }\n",
      "      ], \n",
      "      \"resolved_url\": \"http://feelectronica.de/wp-content/uploads/2015/07/TechnoViking.jpg\", \n",
      "      \"source_url\": \"http://feelectronica.de/wp-content/uploads/2015/07/TechnoViking.jpg\"\n",
      "    }\n",
      "  ], \n",
      "  \"custom_classes\": 0, \n",
      "  \"images_processed\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(visual_recognition.classify(images_url=bildLink), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Resultate ein wenig besser auszulesen, müssen wir die JSON Antwort ein wenig filtern. Dazu speichere ich mal die ganze Antwort in einer Variablen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultat = visual_recognition.classify(images_url=bildLink)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Danach kann man über die eckigen Klammern, einzelne Werte aus der Antwort herausfiltern.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'class': u'Demonstration',\n",
       "  u'score': 0.572,\n",
       "  u'type_hierarchy': u'/person/Demonstration'},\n",
       " {u'class': u'person', u'score': 0.678},\n",
       " {u'class': u'people', u'score': 0.569, u'type_hierarchy': u'/person/people'},\n",
       " {u'class': u'marcher',\n",
       "  u'score': 0.521,\n",
       "  u'type_hierarchy': u'/person/traveler/marcher'},\n",
       " {u'class': u'traveler', u'score': 0.523},\n",
       " {u'class': u'shofar (musical horn)',\n",
       "  u'score': 0.52,\n",
       "  u'type_hierarchy': u'/horn/shofar (musical horn)'},\n",
       " {u'class': u'horn', u'score': 0.52},\n",
       " {u'class': u'crowd', u'score': 0.5, u'type_hierarchy': u'/people/crowd'},\n",
       " {u'class': u'alizarine red color', u'score': 0.801}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultat[\"images\"][0][\"classifiers\"][0][\"classes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diesen Output speichere ich auch wieder in einer Variablen (zwecks besserer übersichtlichkeit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = resultat[\"images\"][0][\"classifiers\"][0][\"classes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit einer Schleife kann ich das ganze wieder auslesen: (Achtung class kann man nicht verwenden, weil es ein spezielles Wort in Python bedeutet):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'score': 0.572, u'class': u'Demonstration', u'type_hierarchy': u'/person/Demonstration'}\n",
      "{u'score': 0.678, u'class': u'person'}\n",
      "{u'score': 0.569, u'class': u'people', u'type_hierarchy': u'/person/people'}\n",
      "{u'score': 0.521, u'class': u'marcher', u'type_hierarchy': u'/person/traveler/marcher'}\n",
      "{u'score': 0.523, u'class': u'traveler'}\n",
      "{u'score': 0.52, u'class': u'shofar (musical horn)', u'type_hierarchy': u'/horn/shofar (musical horn)'}\n",
      "{u'score': 0.52, u'class': u'horn'}\n",
      "{u'score': 0.5, u'class': u'crowd', u'type_hierarchy': u'/people/crowd'}\n",
      "{u'score': 0.801, u'class': u'alizarine red color'}\n"
     ]
    }
   ],
   "source": [
    "for beschreibung in classes:\n",
    "    print beschreibung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Um jede einzele Beschreibung nun auszulesen, kann man schreiben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demonstration\n",
      "person\n",
      "people\n",
      "marcher\n",
      "traveler\n",
      "shofar (musical horn)\n",
      "horn\n",
      "crowd\n",
      "alizarine red color\n"
     ]
    }
   ],
   "source": [
    "for beschreibung in classes:\n",
    "    print beschreibung[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der ganze Code sieht so aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demonstration\n",
      "person\n",
      "people\n",
      "marcher\n",
      "traveler\n",
      "shofar (musical horn)\n",
      "horn\n",
      "crowd\n",
      "alizarine red color\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from os.path import join, dirname\n",
    "from os import environ\n",
    "from watson_developer_cloud import VisualRecognitionV3\n",
    "\n",
    "# verbinde mit der API\n",
    "visual_recognition = VisualRecognitionV3('2016-05-20', api_key='a5c120b7f1e3c757f64b0ba87af00b2d8283c8f6')\n",
    "\n",
    "# definiere das zu untersuchende Bild\n",
    "bildLink = \"http://feelectronica.de/wp-content/uploads/2015/07/TechnoViking.jpg\"\n",
    "\n",
    "# führe die Image Classification durch\n",
    "resultat = visual_recognition.classify(images_url=bildLink)\n",
    "\n",
    "# speichere nur die keywords in einer Variablen (-> Liste)\n",
    "classes = resultat[\"images\"][0][\"classifiers\"][0][\"classes\"]\n",
    "\n",
    "# Lese die Liste mit einer Schleife aus\n",
    "for beschreibung in classes:\n",
    "    print beschreibung[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probiert mal ein anderes Bild und seht eucht die Resultate an."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
